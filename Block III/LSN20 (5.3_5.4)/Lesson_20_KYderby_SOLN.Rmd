---
title: "Kentucky Derby Winning Times"
author: "LTC Starling"
output:
  html_document:
    df_print: paged
  pdf_document: default
---


```{r setup, message=FALSE, echo=TRUE, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, 
      x)
  } else x
}
```

```{r}
# Load packages
library(tidyverse)
library(ggResidpanel)
 
### Data management
ky.dat<-read.table("https://raw.githubusercontent.com/jkstarling/MA376/main/KYDerby18.txt",
                   header=T, 
                   stringsAsFactors = TRUE)


# setwd("C:/Users/james.starling/OneDrive - West Point/Teaching/MA376/JimsLessons/Block III/LSN20/")
# ky.dat <- read.table("KYDerby18.txt", header = TRUE, stringsAsFactors = TRUE)
```

#### Background
Recall that the general form for a linear regression model is:
$$y_i = \beta_0 + \beta_1 x_{1,i}  +  \beta_2x_{2,i} + \cdots + \beta_{n}x_{n,i} + \epsilon_i$$

We can think about this model as having two components, a linear predictor $\beta_0 + \beta_1 x_{1,i} + \beta_{2}x_{2,i} + \cdots + \beta_{n}x_{n,i}$ and a random mechanism that perturbs us from the plane, $\epsilon_i$.

#### Quadratic Models
However, sometimes, we might believe that the relationship between our explanatory and response variable is not linear. This may be for a few different reasons, perhaps the best reason is that we have some previous knowledge that suggests they have a nonlinear relationship. Therefore it might make sense to talk about a general form for statistical models.

The simplest function outside of a linear relationship is if we assume a quadratic model
$$y_i=\beta_0 + \beta_1 x_{1,i} + \beta_2 x_{1,i}^2$$
This is, what our text calls, a polynomial statistical model.  Fitting the model can be achieved in the exact same way as a linear regression model. 

(1) Create a scatterplot of the winning times vs. the years. Describe any patterns you see. Are there any unusual observations? How do you suggest proceeding with the analysis of how the performance of the horses has changed over the years?To see this, let's consider the Kentucky Derby data. For question 1 we create the scatter plot of time vs years.

```{r, fig.height=3, fig.width=5, fig.align='center'}
ky.dat %>% ggplot(aes(x=Year,y=Time)) + geom_point()
```
\vspace{0.5in}



(2) Looks kinda weird...  But as it turns out, the distance changed in 1896, so we're comparing apples to oranges. The Derby was first run at a distance of 1.5 miles but in 1896 the distance changed to its current 1.25 miles (2 kilometers).

Produce a scatterplot of the speeds of the winning horse (in miles per hour) vs. year. What is the overall pattern in these speeds over the years? Why does this pattern make sense in this context? Are there any unusual observations now? (If so, identify by name.) Does it make sense to fit a linear model to these data? 

```{r,fig.height=3, fig.width=5, fig.align='center'}
ky.dat %>% ggplot(aes(x=Year,y=speed)) + geom_point() + geom_text(aes(label = winner), check_overlap = T)
```
\vspace{0.5in}

`r colorize("*There seems to be a cap on the y axis. This isn't uncommon in athletic performance.  We might think about there being a cap on the fastest a horse can possibly run. The one outlier is Kingman. It does not make sense to fit a linear model. There is an obvious curve to the data.*", "blue")`



(3) What type of model might we want to fit? Why? 
\vspace{0.5in}

`r colorize("*It might make sense to fit a quadratic model. (and it was in our reading :-) )*", "blue")`


(4) Fit a quadratic model to predict speed from year and year^2.

```{r}
ky.dat <- ky.dat %>% mutate(Year.sq=Year^2)
poly.lm<-lm(speed ~ Year + Year.sq,data=ky.dat)
summary(poly.lm)
```
\vspace{0.5in}


(5) To check the fit plot the model on your scatterplot.  You can add the model by adding `geom_line()` to your plot.  The `data` for this geom is the model you made above and `.fitted` will provide the model values for your aesthetics. 

```{r, fig.height=3, fig.width=5, fig.align='center'}
ky.dat %>% ggplot(aes(x=Year,y=speed)) + geom_point() + 
  geom_line(aes(x=Year,y=.fitted),data=poly.lm,lwd=1,color="red")
```

(6) Interpret the intercept of this model.

`r colorize("*Predicted speed in year 0.*", "blue")`
\vspace{0.5in}


(7) Write the fitted model or predicted equation. Is the coefficient of year^2 positive or negative, and what does that imply about the relationship between speed and year as year increases? (Hint: You can think of this as an interaction between year and year!)

<span style="color:blue">$$\hat{y} = -988.8 + 1.03year - (2.587*10^{-4})year^2$$ $$se = 0.6024$$</span>
\vspace{0.5in}


(8) Does this model meet our validity conditions?

```{r}
resid_panel(poly.lm, plots = c('hist', 'resid'))
```

`r colorize("*Yes there does not appear to be a pattern in the residuals and the variance is relatively equal.*", "blue")`
\vspace{0.5in}



(9) If we want to use this model to predict, we could use the `predict()` function.  How do we interpret this output?
```{r}
predict(poly.lm,data.frame(Year=2019,Year.sq=2019^2),interval="prediction")
```

`r colorize("*Our predicted speed for the winner in 2019 is 36.65 mph.  Also, we are 95% confident that the winning speed will be between 35.42 and 37.88 mph.*", "blue")`
\vspace{0.5in}


(10) Look at the following code. What does the blue line represent? Does our model perform well? What are some potential issues we may have with our explanatory variables? 

```{r, fig.height=3, fig.width=5, fig.align='center'}
pred.df<-data.frame(y1=35.4,y2=37.8,x1=2019,x2=2019)
ky.dat %>% ggplot(aes(x=Year,y=speed)) + geom_point() + 
  geom_line(aes(x=Year,y=.fitted),data=poly.lm,lwd=1,color="red") + 
  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2),lwd=1,colour = "blue", data = pred.df)
```

`r colorize("The blue line represents the predicted interval at year 2019. Our predicted value is in the middle of the prediction interval. Seems like our model is pretty good. One concern we might have is collinearity or a relationship between our predictors.", "blue")`
\vspace{0.5in}


(11) Create a scatterplot of year^2 and year. What does this tell you?

```{r}
ky.dat %>% ggplot(aes(x = Year, y = Year.sq)) + geom_point()
```

`r colorize("*There is a strong linear relationship between year and $year^2$. We may have colinearity among our explanatory variables.*", "blue")`
\vspace{0.5in}


(12) How can we adjust for this?

`r colorize("*standardize the year and year-squared variables.*", "blue")`
\vspace{0.25in}


(13) Standardize the year and year^2 variables and refit your model.

```{r}
ky.dat.std = ky.dat %>% mutate_at(list(~scale(.)), .vars = vars(Year)) %>% 
  mutate(Year.sq = Year^2)
poly.lm.std<-lm(speed ~ Year + Year.sq,data=ky.dat.std)
summary(poly.lm.std)
ky.dat.std %>% ggplot(aes(x = Year, y = Year.sq))  +  geom_point()
```

(14) Provide an interpretation of the intercept of this model (include units!). 

`r colorize("*The intercept of 35.89 is the predicted average speed in miles per hour in the average year of the data set.  The average year in the data set is 1946.5.*", "blue")`
\vspace{0.5in}


#### Adjusting for track conditions  

(15) If we want to we can adjust for track conditions. Create a model that adjusts for track conditions. To see if the added variables are important we can compare it to the smaller (nested) model via which test?  What are the hypotheses for this test? 

```{r}
levels(factor(ky.dat$condition))
condition.lm<-lm(speed ~ Year  +  Year.sq + condition,data=ky.dat)
summary(condition.lm)
```

`r colorize("We can use the partial-F test", "blue")`

$H_0:$ `r colorize("The extra variables have no effect on y.", "blue")`

$H_a:$ `r colorize("At least one of the extra variables has an effect on y.", "blue")`

\vspace{0.5in}


(16) Conduct the partial-F test between the condition model and the original quadratic model. What are your conclusions?

```{r}
anova(poly.lm, condition.lm)
```

`r colorize("*Based on the high F stat and the low p-value we can conclude that the full model is a better model since at least one of the extra variables has an effect on the response.* ", "blue")`
 \vspace{0.5in}


(17) Would the model you have created be useful in predicting this year’s Kentucky Derby winner? Explain why or why not. (Hint: Consider issues beyond validity conditions.)

`r colorize("*Though the validity conditions are met and there is highly convincing evidence of a significant association to this process, the quadratic model predicts further decrease in the winning speed. This means that the model reflects the current data well, but any future data will be underpredicted. Furthermore, the model created would help us predict the speed of this year’s Kentucky Derby winner, but not so much which horse.*", "blue")`
\vspace{0.5in}


(18) Now let's take a look at the cubic model.  Create a model predicting speed with year, year^2 and year^3. Does this appear to significantly improve the fit?

```{r}
ky.dat.std <- ky.dat.std %>% mutate(Year.3=Year^3)
ky.dat <- ky.dat %>% mutate(Year.3=Year^3)
poly3.lm<-lm(speed ~ Year + Year.sq + Year.3,data=ky.dat.std)
# poly3.lm<-lm(speed ~ Year + Year.sq + Year.3,data=ky.dat)
summary(poly3.lm)
anova(poly.lm, poly3.lm)
```

`r colorize("*The cubic term does not explain significantly more variation in the model. Additionally, none of the terms are significant in the cubic model. The results of the partial-F test also support not needing the cubic model.*", "blue")`
\vspace{0.5in}


(19) Changing gears... try performing transformations on the data. Create scatterplots of  1) log(year) vs. speed; 2) sqrt(year) vs. speed; 3) year-squared vs. speed. Which transformation looks like it has the best fit? Create a linear model

```{r}
ky.dat <- ky.dat %>% mutate(Year.sqrt = sqrt(Year), Year.log = log(Year))
ky.dat %>% ggplot(aes(x=Year.sqrt, y=speed)) + geom_point() + labs(title="sqrt(year) vs speed")
ky.dat %>% ggplot(aes(x=Year.sqrt, y=speed)) + geom_point() + labs(title="sqrt(year) vs speed")
ky.dat %>% ggplot(aes(x=Year.sq, y=speed)) + geom_point() + labs(title="year^2 vs speed")

log.lm <- ky.dat %>% lm(speed ~ Year.log, data = .)
summary(log.lm)
```

`r colorize("All three transformations do not appear to create a linear relationship. Choosing a linear model with log(year) provides a statistically significant result where 64.58% of the variation is explained by the model.", "blue")`
\vspace{0.5in}


(20) An alternative is to use the log transformation but shifted by a value. Create a new variable `log(Year.log - 1874)`. Create a scatterplot of this transformation vs. speed. Does it appear to be more successful? Justify your answer. 
```{r}
my_year <- 1874
ky.dat <- ky.dat %>% mutate(Year.log2 = log(Year - my_year))
ky.dat %>% ggplot(aes(x=Year.log2, y=speed)) + geom_point()
```
\vspace{0.5in}


(21) Create a linear model to predict speed using the updated transformation in (20). What is a 95% prediction interval in 2019?  
```{r}
log.lm2 <- ky.dat %>% lm(speed ~ Year.log2, data = .)
summary(log.lm2)
predict(log.lm2,data.frame(Year.log2=log(2019-my_year)),interval="prediction")
```

`r colorize("*Our predicted speed for the winner in 2019 is 36.89 mph.  Also, we are 95% confident that the winning speed will be between 35.44 and 38.34 mph.*", "blue")`
\vspace{0.5in}

